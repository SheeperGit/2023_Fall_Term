{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oz5KWuuTVCVl"
   },
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xAE_RwTjVFrh"
   },
   "outputs": [],
   "source": [
    "emotions ={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r88IZPL3VOIg"
   },
   "outputs": [],
   "source": [
    "def load_extract_features(data_path):\n",
    "\n",
    "    '''\n",
    "    load_extract_features() is a function that is used to load all the audio files one at a time, compute their features and return the features as well as the target values.\n",
    "\n",
    "    There are around 8-10 audio files which are corrupted. We hardcode zero values for such files in order to maintain consistency.\n",
    "\n",
    "    ['calm', 'happy'] emotion data is categorized into 'positive' and  ['angry', 'fearful'] into 'negative'\n",
    "\n",
    "    Returns:\n",
    "    1. Features\n",
    "    2. Binary Target Values\n",
    "    '''\n",
    "    final_features,target_emotions, binary_label = [],[], []\n",
    "    count = 0\n",
    "\n",
    "    for i in glob.glob(data_path + \"/Actor_*/*.wav\"): #Loop to read every file.\n",
    "\n",
    "        name = os.path.basename(i)\n",
    "        #We split the name of the file to understand the emotion associated with the file.\n",
    "        split = name.split(\"-\")\n",
    "        #We know that the third identifier is associated with the emotion of the audio file. Hence, we use [2] as it represents the third identifier.\n",
    "        emotion = emotions[split[2]]\n",
    "\n",
    "        #Below is the code to categorize the emotions into two classes to make this a binary problem.\n",
    "        if emotion in ['calm', 'happy']:\n",
    "            binary_label.append(0)\n",
    "        elif emotion in ['angry', 'fearful']:\n",
    "            binary_label.append(1)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        with soundfile.SoundFile(i) as audio:\n",
    "            waveform = audio.read(dtype=\"float32\")\n",
    "            sr = audio.samplerate\n",
    "\n",
    "            #Below is the code to extract the Mel spectrogram features\n",
    "            #128 is the standard for machine learning applications using Mel spectrograms\n",
    "            m_feature = librosa.feature.melspectrogram(y=waveform, sr=sr, n_mels=128, fmax=sr / 2.0).T\n",
    "            melspectrogram = np.mean(m_feature,axis=0)\n",
    "            if melspectrogram.shape != (128,):\n",
    "                melspectrogram = np.zeros(128)\n",
    "\n",
    "            #Below is the code to extract the chromagram features\n",
    "            stft_wave = librosa.stft(waveform)\n",
    "            stft = np.abs(stft_wave)\n",
    "            c_feature = librosa.feature.chroma_stft(S=stft, sr=sr).T\n",
    "            chromagram = np.mean(c_feature,axis=0)\n",
    "\n",
    "            #12 is the number of pitch classes\n",
    "            if chromagram.shape != (12,):\n",
    "                chromagram = np.zeros(12)\n",
    "\n",
    "            features=np.array([])\n",
    "            features=np.hstack((chromagram, melspectrogram))\n",
    "\n",
    "            final_features.append(features)\n",
    "            target_emotions.append(emotion)\n",
    "\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                print(\"Processed Audio File Number: \", count)\n",
    "\n",
    "    #We return the features and the binary target values.\n",
    "    return np.array(final_features), np.array(binary_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srmhyLdSVPyV",
    "outputId": "2a564520-9391-4033-ee35-c13df3bb4ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Audio File Number:  100\n",
      "Processed Audio File Number:  200\n",
      "Processed Audio File Number:  300\n",
      "Processed Audio File Number:  400\n",
      "Processed Audio File Number:  500\n",
      "Processed Audio File Number:  600\n",
      "Processed Audio File Number:  700\n"
     ]
    }
   ],
   "source": [
    "#Please change the path below to the path of the folder saved on your computer.\n",
    "\n",
    "# *** NOTE: This is an ABSOLUTE PATH, it won't work on your device! *** #\n",
    "# Either change the tgt dir, or see the (folder) output in: Q5_Audio #\n",
    "data_path = '/home/sean_the_sheep/Desktop/University/2023_Fall_Term/Intro to Machine Learning/A/2/Q5_Audio'\n",
    "X, binary_label = load_extract_features(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "umWCLyyLYGVL"
   },
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(X)\n",
    "df_2 = pd.DataFrame()\n",
    "df_2['label'] = binary_label\n",
    "df = pd.merge(df_1, df_2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7SZk6vLVZrKm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Splitting! Let's do a 70-30 split, as usual #\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, binary_label, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VeQfO3QqakCM"
   },
   "outputs": [],
   "source": [
    "class kNN():\n",
    "  X_data = None\n",
    "  Y_data = None\n",
    "  k = None\n",
    "\n",
    "  def __init__(self, X_train, y_train, k):\n",
    "    self.X_data = X_train\n",
    "    self.Y_data = y_train\n",
    "    self.k = k\n",
    "\n",
    "  def predict(self, x):\n",
    "    X_data = self.X_data\n",
    "    Y_data = self.Y_data\n",
    "    k = self.k\n",
    "    result = []\n",
    "    x_index = np.where(np.all(X_data == x, axis=1))[0]\n",
    "    if x_index.size > 0:\n",
    "        X_data = np.delete(X_data, x_index, axis=0)\n",
    "        Y_data = np.delete(Y_data, x_index)\n",
    "    distances = np.sqrt(np.sum((X_data - x)**2, axis=1))\n",
    "    for i in range(k):\n",
    "        index = np.argmin(distances)\n",
    "        distances[index] = np.inf\n",
    "        result.append(y_train[index])\n",
    "    classify = np.sum(result)/k\n",
    "    if classify >= 0.5:\n",
    "      return 1\n",
    "    return 0\n",
    "\n",
    "  def score(self, x, y):\n",
    "    if self.predict(x) == y:\n",
    "      return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dR1D9q6VpoYf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "num_partitions = 25\n",
    "\n",
    "def optimal_k(knn, X_train, y_train):\n",
    "  kf = StratifiedKFold(n_splits=num_partitions)\n",
    "  k_range = list(range(1, 101))\n",
    "  k_scores = []\n",
    "  \n",
    "  for k in k_range:\n",
    "      total_score = 0\n",
    "      for i, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "        model = knn(X_train[train_index], y_train[train_index], k)\n",
    "        for index in test_index:\n",
    "          test_score = model.score(X_train[index], y_train[index])\n",
    "          total_score += test_score\n",
    "      k_scores.append(total_score/num_partitions)\n",
    "  return k_scores.index(max(k_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M0--NXVgyN2h",
    "outputId": "37269784-fce3-4619-f07d-389b0d7445df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = optimal_k(kNN, X_train, y_train)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRpj58Ohdlo1",
    "outputId": "a0098491-1ac5-4f49-fa37-1ab05f68c7d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 66.79611650485437\n",
      "Training Runtime: 0.3693712319991391\n",
      "Testing Accuracy: 80.54298642533936\n",
      "Testing Runtime: 0.13180899899998622\n"
     ]
    }
   ],
   "source": [
    "init_time = time.perf_counter()\n",
    "preds = []\n",
    "model = kNN(X_train, y_train, k)\n",
    "for row in X_train:\n",
    "  preds.append(model.predict(row))\n",
    "\n",
    "final_time = time.perf_counter()\n",
    "\n",
    "initial_train_accuracy = (np.sum(np.where(y_train - preds == 0, 1, 0))/len(y_train)) * 100\n",
    "initial_train_runtime = final_time - init_time\n",
    "print(\"Training Accuracy: \" + str(initial_train_accuracy))\n",
    "print(\"Training Runtime: \" + str(initial_train_runtime))\n",
    "\n",
    "init_time = time.perf_counter()\n",
    "preds = []\n",
    "model = kNN(X_train, y_train, k)\n",
    "\n",
    "for row in X_test:\n",
    "  preds.append(model.predict(row))\n",
    "\n",
    "final_time = time.perf_counter()\n",
    "\n",
    "init_test_accuracy = (np.sum(np.where(y_test - preds == 0, 1, 0))/len(y_test))  * 100\n",
    "init_test_runtime = final_time - init_time\n",
    "print(\"Testing Accuracy: \" + str(init_test_accuracy))\n",
    "print(\"Testing Runtime: \" + str(init_test_runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hcF0miXh0Kxg"
   },
   "outputs": [],
   "source": [
    "b = np.mean(X, axis=0)\n",
    "cov = np.dot((X - b).T, (X - b))/len(X)\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "\n",
    "max_abs_idx = np.argmax(np.abs(eigenvectors), axis=0)\n",
    "signs = np.sign(eigenvectors[max_abs_idx, range(eigenvectors.shape[0])])\n",
    "eigenvectors = eigenvectors*signs[np.newaxis,:]\n",
    "eigenvectors = eigenvectors.T\n",
    "\n",
    "eigenpairs = [(np.abs(eigenvalues[i]), eigenvectors[:, i]) for i in range(len(eigenvalues))]\n",
    "eigenpairs.sort(key=lambda x: x[0], reverse=True)\n",
    "sorted_eigenvectors = np.array([x[1] for x in eigenpairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5Gm6DMD95xdN"
   },
   "outputs": [],
   "source": [
    "def convert_X(X, i):\n",
    "  W = sorted_eigenvectors[:i, :]\n",
    "  new_X = np.dot((X - b), W.T)\n",
    "  return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Za5b9qgnW6G5",
    "outputId": "0b302953-4c80-44d0-d2af-8acaa2835db9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(736, 38)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 38\n",
    "new_X = convert_X(X, i)\n",
    "new_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIQSYsxlWByX",
    "outputId": "979e38ab-b253-44db-afb8-8ad5cfad0427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Variance Conserved: 99.92185235023499%\n"
     ]
    }
   ],
   "source": [
    "total_Var = np.sum(eigenvalues)\n",
    "\n",
    "Var_conserved = np.sum(eigenvalues[:i]) / total_Var\n",
    "\n",
    "percentage = Var_conserved * 100\n",
    "\n",
    "print(f\"Percentage of Variance Conserved: {percentage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KJJtt6Rx6kpl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Splitting! Let's do a 70-30 split, as usual #\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, binary_label, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSsLQXEVvdY7",
    "outputId": "e9c714ec-c9d6-44b9-e32a-998f222516d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 67.57281553398057\n",
      "Training Runtime: 0.2297173799997836\n",
      "Testing Accuracy: 82.35294117647058\n",
      "Testing Runtime: 0.06583682800010138\n"
     ]
    }
   ],
   "source": [
    "init_time = time.perf_counter()\n",
    "preds = []\n",
    "model = kNN(X_train, y_train, k)\n",
    "\n",
    "for row in X_train:\n",
    "  preds.append(model.predict(row))\n",
    "\n",
    "final_time = time.perf_counter()\n",
    "\n",
    "final_train_accuracy = (np.sum(np.where(y_train - preds == 0, 1, 0))/len(y_train)) * 100\n",
    "final_train_runtime = final_time - init_time\n",
    "print(\"Training Accuracy: \" + str(final_train_accuracy))\n",
    "print(\"Training Runtime: \" + str(final_train_runtime))\n",
    "\n",
    "init_time = time.perf_counter()\n",
    "preds = []\n",
    "model = kNN(X_train, y_train, k)\n",
    "\n",
    "for row in X_test:\n",
    "  preds.append(model.predict(row))\n",
    "\n",
    "final_time = time.perf_counter()\n",
    "\n",
    "final_test_accuracy = (np.sum(np.where(y_test - preds == 0, 1, 0))/len(y_test)) * 100\n",
    "final_test_runtime = final_time - init_time\n",
    "print(\"Testing Accuracy: \" + str(final_test_accuracy))\n",
    "print(\"Testing Runtime: \" + str(final_test_runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVowpCltAQ_L",
    "outputId": "e133e5b9-2405-4c70-c685-8acf78d88e6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy change: 0.7766990291262061\n",
      "Train runtime change: -0.13965385199935554\n",
      "Test accuracy change: 1.8099547511312153\n",
      "Test runtime change: -0.06597217099988484\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy change: \" + str(final_train_accuracy - initial_train_accuracy))\n",
    "print(\"Train runtime change: \" + str(final_train_runtime - initial_train_runtime))\n",
    "print(\"Test accuracy change: \" + str(final_test_accuracy - init_test_accuracy))\n",
    "print(\"Test runtime change: \" + str(final_test_runtime - init_test_runtime))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
